\subsection{Test setup}

Our program was written in C/C++ and compiled with Clang. All memory allocations were cache line boundary aligned. For parallelization we used C++11 cross-platform library \texttt{<thread>}.

All benchmarks were performed on a Linux desktop which has 16 GB ram and a Core i7 3770 CPU with the following specification:

\begin{itemize}
\item 4 * 3.4 GHz (Turbo Boost up to 3.9 GHz)
\item 4 * 32 KB L1 instruction cache
\item 4 * 32 KB L1 data cache (write back)
\item 4 * 256 KB L2 cache (write back)
\item Hyper-Threading
\item Shared 8 MB L3 cache (inclusive, write back)
\item 64 byte cache lines
\item The associativity for the cache levels are 8, 8 and 16 respectively
% http://www.ni.com/white-paper/11266/en#toc5
\end{itemize}

L2 cache faults and L3 cache faults were measured using Intel Performance Monitor Counter while branch mispredictions were measured using PAPI.

All tests were performed 5 times and the median was selected. The data in the matrices were randomly generated double precision floating points with
an uniform distribution. The range of the data was -1 to
1.

\subsection{Simple multiplication}

\subsubsection{Row-based layout}
Figure~\ref{fig:rnrnrn0} shows the measured running time and cache
faults encountered when running the naive matrix multiplier on
matrices with row layout.
\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{plots/rowrow.pdf}
  \caption{Running time and cache faults of naive matrix
    multiplication with all matrices using row layout.}
  \label{fig:rnrnrn0}
\end{figure}

From figure~\ref{rnrnrn0} it seems like we typically gets a bit fewer
cache faults than we expect\todo{Describe why?}. The jumps we expect
also seems to happen, although in the experiments, they seem to happen
a bit before we expect. This can be explained by that the cache also
contains some data which is not the matrices.

Figure~\ref{rnrnrn0} moreover shows a lot of spikes on the lines
indicating L2 and L3 cache faults. The L2 spikes is beginning around
$n = 256$ and the L3 spikes around $n = 1024$.

We strongly suspect that the cache layout due to the 8-way
associativity is to blame. When looking up in the L2 cache, the 36 bit
physical address of the i7 processor is split into three parts $addr =
(tag,index,offset)$. Since the cache line size is $64b$, $6$ bits
should be used to reference a byte in a cache line. Because the L2
cache is $256kb$, we find that the index size to be
\[
  \frac{256 \cdot 1024}{\underbrace{64}_{\text{Cache line size}} \cdot \underbrace{8}_{\text{Cache associativity}}}
    = 512 = 2^9.
\]
Hence, we should use $9$ bits to specify the index. The remaining
$36-6-9=21$ bits is used as tag. Notice that the tag is the most
significant part of the address.

Because the size of our matrices is always divisible by the cache line
size, it will always be the case that a new row in a matrix starts
with a new cache line. But this means that a cache line, and the
corresponding cache lines on the next row, always will be
$\frac{n}{B}$ cache lines apart. Therefore we are only able to utilize
$\ord(\frac{n}{B})$, cache lines in the L2 cache, where $\ord(\dot)$
denotes the order of the element in the additive group
$\mathbb{Z}_{2^9}$.

Figure~\ref{fig:rowrow_cachepeaks} illustrates the correlation between
these available cache lines in the cache (the green line), and the
cache misses divided by the expected number of cache misses (the red
line).

When comparing the interval from $[7.5; 9]$ with the interval $[9;
  10]$, the green line seems to dictate significant more peeks in the
$[9; 10]$ interval. This also makes sense, since the matrices in this
case are bigger, meaning that more columns of the $B$ matrix will be
loaded. Therefore we will overwrite the same available cache slots
more times (we can afford to do this 8 time, since we have an 8-way
cache). The plot on figure~\ref{fig:rowrow_cachepeaks} heavily suggest
that these peaks actually stems from the 8-way cache layout.  The
peaks on the line plotting the L3 cache faults, the peaks can be
described in a similar fashion.

\begin{figure}[h!]
  \centering
  \includegraphics{plots/rowrow_cachepeaks}
  \caption{The number of available cache lines vs. the number of cache
    faults occurring in experiments.}
  \label{fig:rowrow_cachepeaks}
\end{figure}

\subsubsection{Combined row-based and column-based layout}

%\ref{fig:rncnrn0}

%\begin{figure}[h!]
%  \centering
%  \includegraphics[width=\textwidth]{rncnrn0.pdf}
%  \label{fig:rncnrn0}
%\end{figure}

\subsection{Recursive multiplication}

\subsubsection{Z-curve layout}

%\ref{fig:zrzrzr0}

%\begin{figure}[h!]
%  \centering
%  \includegraphics[width=\textwidth]{zrzrzr0.pdf}
%  \label{fig:zrzrzr0}
%\end{figure}

\subsubsection{Tiled layout}

%\begin{figure}[h!]
%  \centering
%  \includegraphics[width=\textwidth]{"../project2/gnuplots/recursive_base_cases"}
%  \caption{Performance of the recursive algorithm with different base case sizes.}
%  \label{fig:recursive_base_cases}
%\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{"../project2/gnuplots/recursive_performance"}
  \label{fig:recursive_layout_performance}
  \caption{Performance comparison between different layouts and the naive row/column algorithm.}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{"../project2/gnuplots/recursive_cache"}
  \label{fig:recursive_layout_cachefaults}
  \caption{Cache faults for each layout.}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{"../project2/gnuplots/recursive_instructions"}
  \label{fig:recursive_layout_instructions}
  \caption{Number of instructions for each layout.}
\end{figure}

\subsection{Strassen}

%\begin{figure}[h!]
%  \centering
%  \includegraphics[width=\textwidth]{"../project2/gnuplots/strassen_base_cases"}
%  \caption{Performance of Strassen with different base case sizes.}
%  \label{fig:recursive_base_cases}
%\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{"../project2/gnuplots/recursive_vs_strassen_performance"}
  \caption{Performance of the best recursive and best Strassen.}
  \label{fig:recursive_vs_strassen_performance}
\end{figure}

Figure \ref{fig:recursive_vs_strassen_performance} shows that Strassen performs better than the tiled recursive algorithm for all the matrix sizes we have tested. However, figure \ref{fig:recursive_vs_strassen_cache} does not give the expected number of cache misses. \todo{hvad var det expected, og hvad ser vi}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{"../project2/gnuplots/recursive_vs_strassen_cache"}
  \caption{Cache misses of the recursive and Strassen. Both with base case 16x16.}
  \label{fig:recursive_vs_strassen_cache}
\end{figure}

%\begin{figure}[h!]
%  \centering
%  \includegraphics[width=\textwidth]{"../project2/plots/4096/row-tiled8x8 recursive-8(tiled-bc)_column-tiled-8x8 recursive-8(generic-bc)_row-tiled8x8 recursive-8(tiled-bc)_0"}
%  \caption{Recursive}
%\end{figure}



%\begin{figure}[h!]
%  \centering
%  \includegraphics[width=\textwidth]{"../project2/plots/4096/z-curve-tiled strassen-32(32-fixed-tiled-bc)_z-curve-tiled strassen-32(32-fixed-tiled-bc)_z-curve-tiled strassen-32(32-fixed-tiled-bc)_0"}
%  \caption{Strassen}
%\end{figure}

\subsection{SIMD instructions}

\begin{figure}[h!]
  \centering
  \missingfigure{Lav graf over performance af bedste rekursive, strassen og maaske en af de naive?}
  \label{fig:simd}
  \caption{Performance with and without SIMD instructions.}
\end{figure}

\subsection{Parallelization}

\begin{figure}[h!]
  \centering
  \missingfigure{Lav graf over performance af Strassen, rekursiv og row/column naiv. 8 core m/ht Og sammenlign med single cpu}
  \label{fig:parallel_performance}
  \caption{Performance of parallelized algorithms.}
\end{figure}

\begin{figure}[h!]
  \centering
  \missingfigure{Lav Amdahls graf over rekursiv, strassen og maaske row/column naiv}
  \label{fig:amdahl}
  \caption{Performance projection using Amdahl's law.}
\end{figure}